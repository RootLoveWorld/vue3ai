import { Ollama ,OllamaEmbeddings} from "@langchain/ollama";
import { PGVectorStore } from "@langchain/community/vectorstores/pgvector";
import { PDFLoader } from "@langchain/community/document_loaders/fs/pdf";
import { TextLoader } from "langchain/document_loaders/fs/text";
import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";
import { Document } from "@langchain/core/documents";

// é…ç½®PostgreSQLè¿æ¥
const config = {
  postgresConnectionOptions: {
    host: "localhost",
    port: 5432,
    user: "postgres",
    password: "123456",
    database: "document",
  },
  tableName: "documents",
  columns: {
    idColumnName: "id",
    embeddingColumnName: "embedding",
    contentColumnName: "content",
    textColumnName: "text",
    metadataColumnName: "metadata",
  },
};

// åˆå§‹åŒ–æ¨¡å‹å’ŒåµŒå…¥
const ollama = new Ollama({
  baseUrl: "http://localhost:11434", 
  model: "qwen3:0.6b",
});

const embeddings = new OllamaEmbeddings({
  model: "qwen3:0.6b", // æ¨èåµŒå…¥æ¨¡å‹
});

// åˆ›å»ºå‘é‡å­˜å‚¨
let vectorStore: PGVectorStore;

async function initVectorStore() {
  vectorStore = await PGVectorStore.initialize(
    embeddings,
    config
  );
}

// æ³¨å…¥æ–°çŸ¥è¯†ï¼ˆPDF/æ–‡æœ¬æ–‡ä»¶ï¼‰
async function injectKnowledge(filePath: string) {
  let loader;
  
  if (filePath.endsWith(".pdf")) {
    loader = new PDFLoader(filePath);
  } else {
    loader = new TextLoader(filePath);
  }

  const rawDocs = await loader.load();
  // æ ¹æ®çŸ¥è¯†ç±»å‹è°ƒæ•´åˆ†å—ç­–ç•¥
  const splitter = new RecursiveCharacterTextSplitter({
    chunkSize: 1000,
    chunkOverlap: 200,
  });
  
  const docs = await splitter.splitDocuments(rawDocs);
  
  await vectorStore.addDocuments(docs);
  console.log(`âœ… æˆåŠŸæ³¨å…¥ ${docs.length} ä¸ªçŸ¥è¯†å—`);
}

// æ‰§è¡ŒRAGæŸ¥è¯¢
async function runRAG(query: string) {
  // 1. ç›¸ä¼¼æ€§æ£€ç´¢
   const results = await vectorStore.similaritySearch(query, 3);

  // åªæœç´¢ç‰¹å®šç±»åˆ«çš„æ–‡æ¡£
  // await vectorStore.similaritySearch(query, 3, { category: "technical" });

   // æ··åˆæ£€ç´¢
   // const results = await vectorStore.hybridSearch(query, 3);

  
  // 2. æ„å»ºæç¤ºè¯
  const context = results.map(r => r.pageContent).join("\n---\n");
  const prompt = `
    è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”ç”¨æˆ·é—®é¢˜ï¼š
    ${context}
    
    ç”¨æˆ·é—®é¢˜ï¼š${query}
    è¦æ±‚ï¼šç­”æ¡ˆå¿…é¡»åŸºäºä¸Šä¸‹æ–‡ï¼Œä¸å…è®¸ç¼–é€ ä¿¡æ¯ã€‚
  `;
  
  // 3. è°ƒç”¨æ¨¡å‹ç”Ÿæˆ
  return await ollama.invoke(prompt);
}

// åˆå§‹åŒ–ç³»ç»Ÿ
async function main() {
  try {
    await initVectorStore();
    
    // æ³¨å…¥åˆå§‹çŸ¥è¯†ï¼ˆå¯é€‰ï¼‰
    // await injectKnowledge("./initial_data.pdf");
    
    // ç¤ºä¾‹æŸ¥è¯¢
    const response = await runRAG("LangChainçš„ä¸»è¦ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ");
    console.log("ğŸ¤– å›ç­”ï¼š", response);
  } catch (error) {
    console.error("ç³»ç»Ÿé”™è¯¯:", error);
  }
}

main();